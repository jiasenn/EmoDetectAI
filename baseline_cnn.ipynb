{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from data folder\n",
    "training_data = datasets.ImageFolder(root='Data/train', transform=ToTensor())\n",
    "test_data = datasets.ImageFolder(root='Data/test', transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([128, 3, 48, 48])\n",
      "Shape of y: torch.Size([128]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# create data loaders\n",
    "batch_size = 128\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (out): Linear(in_features=2304, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         # input shape (3, 48, 48)\n",
    "            nn.Conv2d(\n",
    "                in_channels=3,              # input height\n",
    "                out_channels=16,            # n_filters\n",
    "                kernel_size=5,              # filter size\n",
    "                stride=1,                   # filter movement/step\n",
    "                padding=2,                  # if want same width and length of this image after con2d, padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                              # output shape (16, 48, 48)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(kernel_size=2),    # choose max value in 2x2 area, output shape (16, 112, 112)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         # input shape (16, 24, 24)\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),     # output shape (32, 24, 24)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(2),                # output shape (32, 12, 12)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(         # input shape (32, 12, 12)\n",
    "            nn.Conv2d(32, 64, 5, 1, 2),     # output shape (64, 12, 12)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(2),                # output shape (64, 6, 6)\n",
    "        )\n",
    "\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.out = nn.Linear(64 * 6 * 6, 7)   # 1 connected layer, output 25 classes\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)           # flatten the output of conv2 to (batch_size, 64 * 28 * 28)\n",
    "        output = self.out(x)\n",
    "        return output\n",
    "\n",
    "model = CNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing the model parameters\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "def test(dataloader, model, loss_fn):\n",
    "    test_accuracies = []\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return (100*correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.929655  [    0/28709]\n",
      "loss: 0.092489  [12800/28709]\n",
      "loss: 5.674089  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 17.4%, Avg loss: 1.963865 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.262753  [    0/28709]\n",
      "loss: 0.994994  [12800/28709]\n",
      "loss: 2.938353  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 17.2%, Avg loss: 1.908918 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.992429  [    0/28709]\n",
      "loss: 1.703184  [12800/28709]\n",
      "loss: 2.367054  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.893737 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.969034  [    0/28709]\n",
      "loss: 1.881637  [12800/28709]\n",
      "loss: 1.981582  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 17.2%, Avg loss: 1.890786 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.946090  [    0/28709]\n",
      "loss: 1.827674  [12800/28709]\n",
      "loss: 1.997723  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.878135 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.947940  [    0/28709]\n",
      "loss: 1.779962  [12800/28709]\n",
      "loss: 2.013730  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.867971 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.951071  [    0/28709]\n",
      "loss: 1.737567  [12800/28709]\n",
      "loss: 2.029283  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.859738 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.954990  [    0/28709]\n",
      "loss: 1.699806  [12800/28709]\n",
      "loss: 2.044179  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.853028 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.959342  [    0/28709]\n",
      "loss: 1.666126  [12800/28709]\n",
      "loss: 2.058310  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.847534 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.963886  [    0/28709]\n",
      "loss: 1.636071  [12800/28709]\n",
      "loss: 2.071610  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.843016 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.968451  [    0/28709]\n",
      "loss: 1.609246  [12800/28709]\n",
      "loss: 2.084055  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.839291 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.972927  [    0/28709]\n",
      "loss: 1.585302  [12800/28709]\n",
      "loss: 2.095643  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.836208 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.977229  [    0/28709]\n",
      "loss: 1.563937  [12800/28709]\n",
      "loss: 2.106393  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.833649 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.981304  [    0/28709]\n",
      "loss: 1.544877  [12800/28709]\n",
      "loss: 2.116330  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.831519 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.985123  [    0/28709]\n",
      "loss: 1.527876  [12800/28709]\n",
      "loss: 2.125493  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.829740 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.988659  [    0/28709]\n",
      "loss: 1.512714  [12800/28709]\n",
      "loss: 2.133921  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.828248 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1.991931  [    0/28709]\n",
      "loss: 1.499192  [12800/28709]\n",
      "loss: 2.141661  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.826988 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.994952  [    0/28709]\n",
      "loss: 1.487152  [12800/28709]\n",
      "loss: 2.148747  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.825929 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1.997658  [    0/28709]\n",
      "loss: 1.476425  [12800/28709]\n",
      "loss: 2.155229  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.825033 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 2.000117  [    0/28709]\n",
      "loss: 1.466858  [12800/28709]\n",
      "loss: 2.161156  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.824271 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 2.002333  [    0/28709]\n",
      "loss: 1.458318  [12800/28709]\n",
      "loss: 2.166574  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.823618 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 2.004355  [    0/28709]\n",
      "loss: 1.450729  [12800/28709]\n",
      "loss: 2.171499  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.823060 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 2.006131  [    0/28709]\n",
      "loss: 1.443966  [12800/28709]\n",
      "loss: 2.175987  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.822582 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 2.007713  [    0/28709]\n",
      "loss: 1.437939  [12800/28709]\n",
      "loss: 2.180066  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 17.4%, Avg loss: 3.241183 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 3.011072  [    0/28709]\n",
      "loss: 1.071635  [12800/28709]\n",
      "loss: 25.466883  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 11.6%, Avg loss: 2.834319 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 2.477383  [    0/28709]\n",
      "loss: 0.131602  [12800/28709]\n",
      "loss: 2.438161  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.823143 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 2.041371  [    0/28709]\n",
      "loss: 1.499616  [12800/28709]\n",
      "loss: 2.148174  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.822501 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 2.039205  [    0/28709]\n",
      "loss: 1.487311  [12800/28709]\n",
      "loss: 2.154487  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.821958 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 2.037899  [    0/28709]\n",
      "loss: 1.476356  [12800/28709]\n",
      "loss: 2.160275  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.821508 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 2.036694  [    0/28709]\n",
      "loss: 1.466602  [12800/28709]\n",
      "loss: 2.165576  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.821132 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 2.035572  [    0/28709]\n",
      "loss: 1.457920  [12800/28709]\n",
      "loss: 2.170420  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.820819 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 2.034519  [    0/28709]\n",
      "loss: 1.450190  [12800/28709]\n",
      "loss: 2.174843  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.820556 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 2.033523  [    0/28709]\n",
      "loss: 1.443309  [12800/28709]\n",
      "loss: 2.178878  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.820335 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 2.032577  [    0/28709]\n",
      "loss: 1.437182  [12800/28709]\n",
      "loss: 2.182549  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.820148 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 2.031673  [    0/28709]\n",
      "loss: 1.431728  [12800/28709]\n",
      "loss: 2.185894  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.819989 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 2.030811  [    0/28709]\n",
      "loss: 1.426871  [12800/28709]\n",
      "loss: 2.188935  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.819852 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 2.029983  [    0/28709]\n",
      "loss: 1.422545  [12800/28709]\n",
      "loss: 2.191699  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.819735 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 2.029190  [    0/28709]\n",
      "loss: 1.418693  [12800/28709]\n",
      "loss: 2.194209  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.819633 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 2.028431  [    0/28709]\n",
      "loss: 1.415260  [12800/28709]\n",
      "loss: 2.196487  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.819545 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 2.027703  [    0/28709]\n",
      "loss: 1.412202  [12800/28709]\n",
      "loss: 2.198555  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.819467 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 2.027004  [    0/28709]\n",
      "loss: 1.409476  [12800/28709]\n",
      "loss: 2.200428  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.819399 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 2.026336  [    0/28709]\n",
      "loss: 1.407046  [12800/28709]\n",
      "loss: 2.202128  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.819339 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 2.025696  [    0/28709]\n",
      "loss: 1.404878  [12800/28709]\n",
      "loss: 2.203667  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.819285 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 2.025083  [    0/28709]\n",
      "loss: 1.402944  [12800/28709]\n",
      "loss: 2.205060  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.819237 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 2.024498  [    0/28709]\n",
      "loss: 1.401218  [12800/28709]\n",
      "loss: 2.206321  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.819194 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 2.023940  [    0/28709]\n",
      "loss: 1.399676  [12800/28709]\n",
      "loss: 2.207459  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.819155 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 2.023407  [    0/28709]\n",
      "loss: 1.398298  [12800/28709]\n",
      "loss: 2.208491  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.819120 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 2.022899  [    0/28709]\n",
      "loss: 1.397067  [12800/28709]\n",
      "loss: 2.209422  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.819088 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 2.022415  [    0/28709]\n",
      "loss: 1.395965  [12800/28709]\n",
      "loss: 2.210262  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.819059 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 2.021954  [    0/28709]\n",
      "loss: 1.394979  [12800/28709]\n",
      "loss: 2.211019  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.819032 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "test_accuracies = []\n",
    "# Training and testing the model\n",
    "epochs = 50\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    acc = test(test_dataloader, model, loss_fn)\n",
    "    test_accuracies.append(acc)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_axis = [i for i in range(1, epochs+1)]\n",
    "plt.plot(x_axis, test_accuracies)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
