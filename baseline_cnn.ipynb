{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from data folder\n",
    "training_data = datasets.ImageFolder(root='Data_E/train', transform=ToTensor())\n",
    "test_data = datasets.ImageFolder(root='Data_E/test', transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([128, 3, 48, 48])\n",
      "Shape of y: torch.Size([128]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# create data loaders\n",
    "batch_size = 128\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (out): Linear(in_features=2304, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         # input shape (3, 48, 48)\n",
    "            nn.Conv2d(\n",
    "                in_channels=3,              # input height\n",
    "                out_channels=16,            # n_filters\n",
    "                kernel_size=5,              # filter size\n",
    "                stride=1,                   # filter movement/step\n",
    "                padding=2,                  # if want same width and length of this image after con2d, padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                              # output shape (16, 48, 48)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(kernel_size=2),    # choose max value in 2x2 area, output shape (16, 112, 112)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         # input shape (16, 24, 24)\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),     # output shape (32, 24, 24)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(2),                # output shape (32, 12, 12)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(         # input shape (32, 12, 12)\n",
    "            nn.Conv2d(32, 64, 5, 1, 2),     # output shape (64, 12, 12)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(2),                # output shape (64, 6, 6)\n",
    "        )\n",
    "\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.out = nn.Linear(64 * 6 * 6, 7)   # 1 connected layer, output 25 classes\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)           # flatten the output of conv2 to (batch_size, 64 * 28 * 28)\n",
    "        output = self.out(x)\n",
    "        return output\n",
    "\n",
    "model = CNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing the model parameters\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "def test(dataloader, model, loss_fn):\n",
    "    test_accuracies = []\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return (100*correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.929655  [    0/28709]\n",
      "loss: 0.092489  [12800/28709]\n",
      "loss: 5.674089  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 17.4%, Avg loss: 1.963865 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.262753  [    0/28709]\n",
      "loss: 0.994994  [12800/28709]\n",
      "loss: 2.938353  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 17.2%, Avg loss: 1.908918 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.992429  [    0/28709]\n",
      "loss: 1.703184  [12800/28709]\n",
      "loss: 2.367054  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.893737 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.969034  [    0/28709]\n",
      "loss: 1.881637  [12800/28709]\n",
      "loss: 1.981582  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 17.2%, Avg loss: 1.890786 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.946090  [    0/28709]\n",
      "loss: 1.827674  [12800/28709]\n",
      "loss: 1.997723  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.878135 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.947940  [    0/28709]\n",
      "loss: 1.779962  [12800/28709]\n",
      "loss: 2.013730  [25600/28709]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.867971 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.951071  [    0/28709]\n",
      "loss: 1.737567  [12800/28709]\n"
     ]
    }
   ],
   "source": [
    "test_accuracies = []\n",
    "# Training and testing the model\n",
    "epochs = 50\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    acc = test(test_dataloader, model, loss_fn)\n",
    "    test_accuracies.append(acc)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_axis = [i for i in range(1, epochs+1)]\n",
    "plt.plot(x_axis, test_accuracies)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
